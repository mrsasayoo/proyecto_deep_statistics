# Proyecto 1 - SituaciÃ³n 2: Clustering para EvaluaciÃ³n AgroecolÃ³gica

## ğŸ¯ Contexto del Problema

Una agencia de gestiÃ³n agrÃ­cola necesita realizar una **evaluaciÃ³n rÃ¡pida del estado de la cobertura terrestre** en una regiÃ³n vulnerable despuÃ©s de un **evento climÃ¡tico extremo** (sequÃ­a o inundaciÃ³n). 

**DesafÃ­o:** No poseen etiquetas actualizadas (ground truth) de la zona, pero tienen acceso a miles de imÃ¡genes satelitales de alta resoluciÃ³n.

**Objetivo:** Utilizar **clustering no supervisado** para agrupar imÃ¡genes en categorÃ­as que representen diferentes tipologÃ­as de cobertura terrestre (cultivo saludable, bosque denso, suelo desnudo, zona inundada). 

**HipÃ³tesis:** Los clÃºsteres que representen "suelo desnudo", "zona industrial" o "agua estancada" son **indicadores de zonas agroecolÃ³gicas daÃ±adas o en estrÃ©s**.

---

## ğŸ“Š Fuente de Datos

**Dataset:** EuroSAT - Land Use and Land Cover Classification with Sentinel-2

- **Total imÃ¡genes:** 27,000 imÃ¡genes satelitales multiespectrales
- **ResoluciÃ³n:** 64Ã—64 pÃ­xeles
- **Bandas espectrales:** 13 bandas del satÃ©lite Sentinel-2
- **TamaÃ±o:** ~2.1 GB (versiÃ³n Multiespectral)
- **10 Clases (solo para validaciÃ³n final):**
  - AnnualCrop (Cultivo Anual)
  - PermanentCrop (Cultivo Permanente)
  - Pasture (Pasto)
  - Forest (Bosque)
  - HerbaceousVegetation (VegetaciÃ³n HerbÃ¡cea)
  - Industrial (Zona Industrial)
  - Residential (Zona Residencial)
  - SeaLake (Mar/Lago)
  - River (RÃ­o)
  - Highway (Carretera)

**âš ï¸ Importante:** Las etiquetas reales solo se utilizarÃ¡n al final para **validaciÃ³n externa**, manteniendo el enfoque no supervisado del clustering.

---

## ğŸ—‚ï¸ OrganizaciÃ³n del Proyecto

Dado que vas a manejar el dataset **Multiespectral (MS)** de 2.1 GB, la organizaciÃ³n es clave para no saturar la memoria RAM y para que tu flujo de trabajo sea profesional.

AquÃ­ tienes la propuesta de estructura de directorios y el plan granular paso a paso.

---

### 1. Estructura de Directorios Completa y Predicha

Esta estructura muestra TODOS los archivos y carpetas que se generarÃ¡n durante el proyecto:

```text
situacion_2/
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ EuroSAT_MS/                    # Datos crudos (.tif) - 2.1 GB
â”‚   â”‚   â”œâ”€â”€ AnnualCrop/                # ~3,000 imÃ¡genes .tif
â”‚   â”‚   â”œâ”€â”€ Forest/
â”‚   â”‚   â”œâ”€â”€ HerbaceousVegetation/
â”‚   â”‚   â”œâ”€â”€ Highway/
â”‚   â”‚   â”œâ”€â”€ Industrial/
â”‚   â”‚   â”œâ”€â”€ Pasture/
â”‚   â”‚   â”œâ”€â”€ PermanentCrop/
â”‚   â”‚   â”œâ”€â”€ Residential/
â”‚   â”‚   â”œâ”€â”€ River/
â”‚   â”‚   â””â”€â”€ SeaLake/
â”‚   â””â”€â”€ EuroSAT_MS.zip                 # Archivo original (backup)
â”‚
â”œâ”€â”€ data_processed/                    # âš¡ Datos procesados listos para usar
â”‚   â”œâ”€â”€ .checkpoints/                  # ğŸ”’ Control de ejecuciÃ³n secuencial
â”‚   â”‚   â”œâ”€â”€ 01_data_loading.done
â”‚   â”‚   â”œâ”€â”€ 02_normalization.done
â”‚   â”‚   â”œâ”€â”€ 03_pca_reduction.done
â”‚   â”‚   â”œâ”€â”€ 04_kmeans_clustering.done
â”‚   â”‚   â”œâ”€â”€ 05_dbscan_clustering.done
â”‚   â”‚   â””â”€â”€ 06_evaluation_validation.done
â”‚   â”œâ”€â”€ metadata_labels.csv            # [image_id, true_label, file_path]
â”‚   â”œâ”€â”€ features_raw_flattened.npy     # Matriz (27000 x 53248) - ~10 GB [OPCIONAL]
â”‚   â”œâ”€â”€ features_normalized.npy        # Matriz normalizada (27000 x 53248)
â”‚   â”œâ”€â”€ features_pca_reduced.csv       # â­ Matriz reducida (27000 x m) - LIGERA
â”‚   â”œâ”€â”€ pca_variance_explained.csv     # Varianza por componente
â”‚   â””â”€â”€ processing_log.txt             # Log de tiempos de procesamiento
â”‚
â”œâ”€â”€ src/                               # ğŸ“œ Scripts de procesamiento secuencial
â”‚   â”œâ”€â”€ config.py                      # ConfiguraciÃ³n global (paths, constantes)
â”‚   â”œâ”€â”€ 01_data_loading.py             # Carga y aplanamiento de imÃ¡genes
â”‚   â”œâ”€â”€ 02_normalization.py            # NormalizaciÃ³n con StandardScaler
â”‚   â”œâ”€â”€ 03_pca_reduction.py            # ReducciÃ³n dimensional con PCA
â”‚   â”œâ”€â”€ 04_kmeans_clustering.py        # Modelado K-Means con optimizaciÃ³n k
â”‚   â”œâ”€â”€ 05_dbscan_clustering.py        # Modelado DBSCAN con GridSearch
â”‚   â”œâ”€â”€ 06_evaluation_validation.py    # MÃ©tricas ARI, NMI, Silueta
â”‚   â”œâ”€â”€ 07_visualization_export.py     # GeneraciÃ³n de todas las figuras
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ image_loader.py            # Funciones de carga eficiente
â”‚       â”œâ”€â”€ memory_utils.py            # GestiÃ³n de memoria y liberaciÃ³n
â”‚       â””â”€â”€ plotting_utils.py          # Funciones de visualizaciÃ³n
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ situacion_2.ipynb              # ğŸ““ Notebook principal integrado
â”‚   â”œâ”€â”€ 01_exploratory_analysis.ipynb  # EDA de imÃ¡genes (opcional)
â”‚   â””â”€â”€ 02_debug_testing.ipynb         # Testing con subset pequeÃ±o
â”‚
â”œâ”€â”€ outputs/                           # ğŸ“Š Resultados finales
â”‚   â”œâ”€â”€ models/                        # Modelos entrenados persistidos
â”‚   â”‚   â”œâ”€â”€ pca_model.pkl              # Modelo PCA (para reproducibilidad)
â”‚   â”‚   â”œâ”€â”€ scaler_model.pkl           # StandardScaler (para nuevos datos)
â”‚   â”‚   â”œâ”€â”€ kmeans_model.pkl           # Modelo K-Means final
â”‚   â”‚   â”œâ”€â”€ dbscan_model.pkl           # Modelo DBSCAN final
â”‚   â”‚   â”œâ”€â”€ kmeans_labels.npy          # Etiquetas de clÃºster K-Means
â”‚   â”‚   â””â”€â”€ dbscan_labels.npy          # Etiquetas de clÃºster DBSCAN
â”‚   â”‚
â”‚   â”œâ”€â”€ figures/                       # ğŸ¨ GrÃ¡ficos para el informe
â”‚   â”‚   â”œâ”€â”€ 01_pca/
â”‚   â”‚   â”‚   â”œâ”€â”€ variance_explained_cumulative.png
â”‚   â”‚   â”‚   â”œâ”€â”€ scree_plot.png
â”‚   â”‚   â”‚   â””â”€â”€ pca_2d_projection.png  # ProyecciÃ³n primeros 2 componentes
â”‚   â”‚   â”œâ”€â”€ 02_kmeans/
â”‚   â”‚   â”‚   â”œâ”€â”€ elbow_plot_sse.png     # GrÃ¡fico del Codo
â”‚   â”‚   â”‚   â”œâ”€â”€ silhouette_scores.png  # Coeficientes de Silueta por k
â”‚   â”‚   â”‚   â”œâ”€â”€ clusters_pca_space.png # VisualizaciÃ³n en espacio PCA
â”‚   â”‚   â”‚   â””â”€â”€ sample_images_per_cluster/ # ImÃ¡genes representativas
â”‚   â”‚   â”‚       â”œâ”€â”€ cluster_0_samples.png
â”‚   â”‚   â”‚       â”œâ”€â”€ cluster_1_samples.png
â”‚   â”‚   â”‚       â””â”€â”€ ... (hasta cluster_k)
â”‚   â”‚   â”œâ”€â”€ 03_dbscan/
â”‚   â”‚   â”‚   â”œâ”€â”€ k_distance_graph.png   # GrÃ¡fico para determinar epsilon
â”‚   â”‚   â”‚   â”œâ”€â”€ clusters_dbscan.png    # ClÃºsteres encontrados
â”‚   â”‚   â”‚   â”œâ”€â”€ outliers_analysis.png  # VisualizaciÃ³n de anomalÃ­as
â”‚   â”‚   â”‚   â””â”€â”€ noise_sample_images.png # ImÃ¡genes clasificadas como ruido
â”‚   â”‚   â”œâ”€â”€ 04_evaluation/
â”‚   â”‚   â”‚   â”œâ”€â”€ confusion_matrix_kmeans.png
â”‚   â”‚   â”‚   â”œâ”€â”€ confusion_matrix_dbscan.png
â”‚   â”‚   â”‚   â”œâ”€â”€ confusion_matrix_kmeans_normalized.png
â”‚   â”‚   â”‚   â”œâ”€â”€ confusion_matrix_dbscan_normalized.png
â”‚   â”‚   â”‚   â””â”€â”€ metrics_comparison_table.png # ARI, NMI, Silueta
â”‚   â”‚   â””â”€â”€ 05_interpretation/
â”‚   â”‚       â”œâ”€â”€ cluster_composition_heatmap.png
â”‚   â”‚       â”œâ”€â”€ stress_zones_distribution.png
â”‚   â”‚       â””â”€â”€ crops_vs_forests_separation.png
â”‚   â”‚
â”‚   â”œâ”€â”€ tables/                        # ğŸ“‹ Tablas cuantitativas
â”‚   â”‚   â”œâ”€â”€ pca_components_variance.csv
â”‚   â”‚   â”œâ”€â”€ kmeans_optimization_results.csv
â”‚   â”‚   â”œâ”€â”€ dbscan_hyperparameters.csv
â”‚   â”‚   â”œâ”€â”€ metrics_comparison.csv     # ARI, NMI, Silueta
â”‚   â”‚   â””â”€â”€ cluster_characterization.csv # ComposiciÃ³n de cada clÃºster
â”‚   â”‚
â”‚   â””â”€â”€ reports/                       # ğŸ“„ Documentos finales
â”‚       â”œâ”€â”€ informe_situacion_2.pdf    # Informe final (<25 pÃ¡ginas)
â”‚       â”œâ”€â”€ presentacion.pptx          # PresentaciÃ³n opcional
â”‚       â””â”€â”€ README_RESULTADOS.md       # Resumen ejecutivo
â”‚
â”œâ”€â”€ docs/                              # ğŸ“š DocumentaciÃ³n del proyecto
â”‚   â”œâ”€â”€ metodologia.md                 # JustificaciÃ³n tÃ©cnica
â”‚   â””â”€â”€ referencias.bib                # Referencias bibliogrÃ¡ficas
â”‚
â”œâ”€â”€ plan_maestro.md                    # ğŸ¯ Este archivo - GuÃ­a completa
â”œâ”€â”€ README.md                          # DescripciÃ³n general del proyecto
â””â”€â”€ requirements.txt                   # Dependencias Python
```

---

### ğŸ”’ Sistema de Control de EjecuciÃ³n Secuencial

**Carpeta crÃ­tica:** `data_processed/.checkpoints/`

Cada script de procesamiento crea un archivo `.done` al finalizar exitosamente. Los scripts subsecuentes validan la existencia de estos archivos antes de ejecutarse.

**Flujo de validaciÃ³n:**
```
01_data_loading.py â†’ crea 01_data_loading.done
02_normalization.py â†’ valida 01_data_loading.done â†’ crea 02_normalization.done
03_pca_reduction.py â†’ valida 02_normalization.done â†’ crea 03_pca_reduction.done
... y asÃ­ sucesivamente
```

**âš ï¸ REGLA CRÃTICA:** Nunca ejecutar dos scripts de procesamiento simultÃ¡neamente para evitar saturaciÃ³n de RAM.

---

### ğŸ“Š TamaÃ±os Estimados de Archivos

| Archivo | TamaÃ±o Aproximado | DescripciÃ³n |
|---------|-------------------|-------------|
| `dataset/EuroSAT_MS/` | ~2.1 GB | Datos crudos originales |
| `features_raw_flattened.npy` | ~10 GB | Matriz completa aplanada (opcional) |
| `features_normalized.npy` | ~10 GB | Matriz normalizada |
| `features_pca_reduced.csv` | ~50-200 MB | â­ Matriz reducida (ligera) |
| Modelos `.pkl` | ~10-100 MB cada uno | Modelos entrenados |
| Figuras `.png` | ~500 KB - 2 MB cada una | GrÃ¡ficos de alta resoluciÃ³n |

**Total espacio requerido:** ~25-30 GB (incluyendo datos temporales)

---

### 2. Plan Granular Paso a Paso

He dividido el plan en **5 fases** que siguen la lÃ³gica del taller:

## âš¡ DIAGRAMA DE FLUJO DE EJECUCIÃ“N SECUENCIAL

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ”’ PIPELINE SECUENCIAL - EJECUCIÃ“N OBLIGATORIA EN ORDEN        â”‚
â”‚  âš ï¸  NO ejecutar pasos en paralelo (saturaciÃ³n de RAM)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 1: 01_data_loading.py                    â”‚
    â”‚ Carga 27,000 imÃ¡genes .tif (13 bandas)        â”‚
    â”‚ Output: features_raw_flattened.npy (10 GB)    â”‚
    â”‚ Tiempo: ~15-30 min                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ âœ“ checkpoint: 01_data_loading.done
                            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 2: 02_normalization.py                   â”‚
    â”‚ Normaliza con StandardScaler                  â”‚
    â”‚ Output: features_normalized.npy               â”‚
    â”‚ Tiempo: ~5-10 min                              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ âœ“ checkpoint: 02_normalization.done
                            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 3: 03_pca_reduction.py                   â”‚
    â”‚ PCA: 53,248 â†’ ~50-200 componentes             â”‚
    â”‚ Output: features_pca_reduced.csv (ligero)     â”‚
    â”‚ Tiempo: ~10-20 min                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ âœ“ checkpoint: 03_pca_reduction.done
                            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 4: 04_kmeans_clustering.py               â”‚
    â”‚ K-Means con k=2..15, Codo + Silueta           â”‚
    â”‚ Output: kmeans_model.pkl + labels             â”‚
    â”‚ Tiempo: ~20-40 min                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ âœ“ checkpoint: 04_kmeans_clustering.done
                            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 5: 05_dbscan_clustering.py               â”‚
    â”‚ DBSCAN con optimizaciÃ³n de epsilon            â”‚
    â”‚ Output: dbscan_model.pkl + labels             â”‚
    â”‚ Tiempo: ~15-30 min                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ âœ“ checkpoint: 05_dbscan_clustering.done
                            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 6: 06_evaluation_validation.py           â”‚
    â”‚ Matrices confusiÃ³n, ARI, NMI, Silueta         â”‚
    â”‚ Output: tablas de mÃ©tricas                    â”‚
    â”‚ Tiempo: ~5-10 min                              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ âœ“ checkpoint: 06_evaluation_validation.done
                            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PASO 7: 07_visualization_export.py            â”‚
    â”‚ Genera todas las figuras para informe         â”‚
    â”‚ Output: ~20 grÃ¡ficos en outputs/figures/      â”‚
    â”‚ Tiempo: ~10-20 min                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ âœ“ checkpoint: 07_visualization_export.done
                            â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ âœ… PIPELINE COMPLETADO         â”‚
            â”‚ Total: ~80-160 minutos         â”‚
            â”‚ Listo para redactar informe   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ¯ EjecuciÃ³n AutomÃ¡tica del Pipeline

**OpciÃ³n 1: Script Master (Recomendado)**
```bash
python run_pipeline.py
```

Este script:
- âœ… Ejecuta todos los pasos EN ORDEN automÃ¡ticamente
- âœ… Valida checkpoints antes de cada paso
- âœ… Pausa 5 segundos entre pasos para liberar RAM
- âœ… Muestra tiempo estimado y progreso
- âœ… Permite continuar desde donde quedÃ³ si falla

**OpciÃ³n 2: EjecuciÃ³n Manual Paso a Paso**
```bash
python src/01_data_loading.py
# Esperar a que termine completamente
python src/02_normalization.py
# Esperar a que termine completamente
python src/03_pca_reduction.py
# ... y asÃ­ sucesivamente
```

âš ï¸ **NUNCA ejecutar dos scripts simultÃ¡neamente** (ej: abrir dos terminales).

---

### 2.1. Detalles de Cada Fase

#### Fase 1: IngenierÃ­a de Datos y ReducciÃ³n Dimensional ($n \times p \to n \times m$)

**Objetivo:** Transformar 27,000 imÃ¡genes multiespectrales de alta dimensionalidad en una matriz compacta lista para clustering.

*   **Paso 1.1:** **Lectura eficiente de imÃ¡genes `.tif`:**
    *   Usar `tifffile` o `rasterio` para leer las 13 bandas espectrales.
    *   Implementar procesamiento por lotes para no saturar la RAM (~1,000 imÃ¡genes por lote).
    *   Verificar dimensiones: cada imagen debe ser $(64 \times 64 \times 13)$.
    
*   **Paso 1.2:** **ExtracciÃ³n de metadatos:**
    *   Extraer etiquetas reales desde los nombres de carpetas (AnnualCrop, Forest, etc.).
    *   **Importante:** Estas etiquetas NO se usan para el clustering, solo para validaciÃ³n final.
    *   Guardar en un DataFrame: `[image_id, true_label, file_path]`.
    
*   **Paso 1.3:** **Aplanamiento (Flattening):**
    *   Aplanar cada imagen de $(64 \times 64 \times 13)$ a un vector de $p = 53,248$ elementos.
    *   Resultado: Matriz de caracterÃ­sticas $(n \times p)$ donde $n \approx 27,000$ y $p = 53,248$.
    
*   **Paso 1.4:** **NormalizaciÃ³n:**
    *   Aplicar `StandardScaler` de scikit-learn sobre la matriz completa.
    *   RazÃ³n: Los valores de reflectancia satelital varÃ­an significativamente entre bandas (visibles vs. infrarrojas).
    *   La normalizaciÃ³n es **crÃ­tica** para que PCA funcione correctamente.
    
*   **Paso 1.5:** **ReducciÃ³n de Dimensionalidad (PCA):**
    *   Aplicar PCA para reducir de $p = 53,248$ a $m$ componentes.
    *   Criterio: Retener componentes que expliquen >90% de la varianza acumulada.
    *   Meta esperada: $m \approx 50-200$ componentes (reducciÃ³n drÃ¡stica de dimensionalidad).
    *   Generar grÃ¡fico de varianza explicada acumulada.
    
*   **Paso 1.6:** **Persistencia de datos procesados:**
    *   Guardar matriz reducida $(n \times m)$ en `data_processed/features_pca.csv`.
    *   Guardar tambiÃ©n el modelo PCA en `outputs/models/pca_model.pkl` para reproducibilidad.
    *   **Beneficio:** A partir de aquÃ­, trabajas con datos ligeros y el procesamiento es instantÃ¡neo.

#### Fase 2: Modelado de Clustering - K-Means
*   **Paso 2.1:** **OptimizaciÃ³n de K:** Ejecutar K-means para $k$ de 2 a 15.
*   **Paso 2.2:** Generar **GrÃ¡fico del Codo (SSE)** - Suma de Errores CuadrÃ¡ticos dentro de cada clÃºster.
*   **Paso 2.3:** Generar **GrÃ¡fico de Coeficiente de Silueta** - MÃ©trica clave para determinar la calidad de la separaciÃ³n entre clÃºsteres.
*   **Paso 2.4:** **Elegir el $k$ Ã³ptimo** basado en los grÃ¡ficos. **HipÃ³tesis del proyecto:** $k$ Ã³ptimo entre 8 a 12 clÃºsteres (correspondiente aproximadamente al nÃºmero de clases reales).
*   **Paso 2.5:** Ajustar el modelo K-Means final con el $k$ Ã³ptimo y asignar etiquetas de clÃºster a cada imagen.
*   **Paso 2.6:** Guardar el modelo entrenado en `outputs/models/kmeans_model.pkl`.

#### Fase 3: Modelado de Clustering - DBSCAN (Density-Based Spatial Clustering)
*   **Paso 3.1:** **BÃºsqueda de hiperparÃ¡metros Ã³ptimos:**
    *   `epsilon` ($\epsilon$): Distancia mÃ¡xima entre dos puntos para ser considerados vecinos. *Pista: usar el mÃ©todo de la rodilla (k-distance graph) con vecinos cercanos para determinar $\epsilon$.*
    *   `min_samples`: NÃºmero mÃ­nimo de puntos en un vecindario para formar un clÃºster denso.
*   **Paso 3.2:** **JustificaciÃ³n de hiperparÃ¡metros:** Documentar cÃ³mo se eligieron $\epsilon$ y `min_samples` basÃ¡ndose en la naturaleza de los datos espectrales.
*   **Paso 3.3:** Ejecutar DBSCAN sobre los datos reducidos de PCA.
*   **Paso 3.4:** **AnÃ¡lisis de Resultados:** 
    *   Â¿CuÃ¡ntos clÃºsteres detecta DBSCAN?
    *   Â¿Identifica muchas imÃ¡genes como `-1` (ruido/anomalÃ­as)?
*   **Paso 3.5:** **AnÃ¡lisis de Ruido (Outliers):** Identificar y visualizar imÃ¡genes marcadas como anomalÃ­as. Pregunta clave: Â¿Son nubes, errores de sensor, o cobertura terrestre anÃ³mala?
*   **Paso 3.6:** Guardar el modelo y las asignaciones de clÃºsteres en `outputs/models/dbscan_model.pkl`.

#### Fase 4: EvaluaciÃ³n y ValidaciÃ³n Externa
*   **Paso 4.1:** **ValidaciÃ³n Interna:** 
    *   Calcular y comparar el **Coeficiente de Silueta** promedio entre K-Means y DBSCAN.
    *   El modelo con mayor Coeficiente de Silueta tiene mejor separaciÃ³n interna entre clÃºsteres.
*   **Paso 4.2:** **ValidaciÃ³n Externa (Usando las Etiquetas Ocultas):**
    *   Ahora, y **solo para validar**, utilice las etiquetas reales del dataset EuroSAT (AnnualCrop, Industrial, Forest, etc.).
    *   **Matriz de ConfusiÃ³n:** Cruzar los $k$ clÃºsteres encontrados (Cluster 0, Cluster 1...) con las 10 clases reales.
    *   Generar matrices de confusiÃ³n separadas para K-Means y DBSCAN.
*   **Paso 4.3:** **MÃ©tricas de Concordancia:**
    *   **ARI (Adjusted Rand Index):** Mide la similitud entre las agrupaciones encontradas y las etiquetas reales, ajustado por el azar. Rango: [-1, 1], donde 1 = concordancia perfecta.
    *   **NMI (Normalized Mutual Information):** Cuantifica la informaciÃ³n compartida entre clÃºsteres y clases reales. Rango: [0, 1], donde 1 = concordancia perfecta.
    *   Reportar ARI y NMI para ambos algoritmos.
*   **Paso 4.4:** **SelecciÃ³n del Mejor Modelo:** Comparar K-Means vs DBSCAN usando:
    *   Coeficiente de Silueta (validaciÃ³n interna)
    *   ARI y NMI (validaciÃ³n externa)
    *   Capacidad de detectar anomalÃ­as (ventaja de DBSCAN)

#### Fase 5: Perfilado e InterpretaciÃ³n AgroecolÃ³gica (ConclusiÃ³n del Proyecto)
*   **Paso 5.1:** **AnÃ¡lisis de ComposiciÃ³n de ClÃºsteres:**
    *   Para cada clÃºster, analizar quÃ© clases reales predominan (usando la matriz de confusiÃ³n).
    *   Crear tabla resumen: ClÃºster â†’ Clases dominantes â†’ InterpretaciÃ³n.
*   **Paso 5.2:** **IdentificaciÃ³n de Zonas en EstrÃ©s AgroecolÃ³gico:**
    *   Responder: Â¿QuÃ© clÃºsteres representan **"suelo desnudo"**, **"zona industrial"** o **"agua estancada"**?
    *   Estos clÃºsteres son **indicadores de zonas agroecolÃ³gicas daÃ±adas o en estrÃ©s**.
    *   Â¿CuÃ¡ntas imÃ¡genes de la regiÃ³n estÃ¡n en estos clÃºsteres de alto riesgo?
*   **Paso 5.3:** **SeparaciÃ³n Cultivos vs. Bosques:**
    *   Pregunta clave del PDF: Â¿Se separaron claramente los **Cultivos** (AnnualCrop, PermanentCrop) de los **Bosques** (Forest)?
    *   Gracias a las **13 bandas espectrales** de Sentinel-2, esta separaciÃ³n deberÃ­a ser muy clara en los clÃºsteres.
*   **Paso 5.4:** **Ventaja del Enfoque Multiespectral:**
    *   Discutir cÃ³mo las 13 bandas (incluyendo infrarrojo cercano e infrarrojo de onda corta) permitieron detectar diferencias sutiles que serÃ­an invisibles en imÃ¡genes RGB convencionales.
*   **Paso 5.5:** **ConclusiÃ³n AgroecolÃ³gica Final:**
    *   Sintetizar hallazgos para la agencia: 
        - Â¿QuÃ© porcentaje del territorio estÃ¡ en estado saludable vs. en estrÃ©s?
        - Â¿QuÃ© regiones requieren intervenciÃ³n inmediata post-evento climÃ¡tico?
        - Â¿El clustering no supervisado fue efectivo para este diagnÃ³stico rÃ¡pido sin ground truth actualizado?

---

### 3. Requisitos TÃ©cnicos

**LibrerÃ­as Necesarias:**
```bash
pip install tifffile scikit-learn pandas numpy matplotlib seaborn
pip install rasterio  # Alternativa robusta para leer GeoTIFF
```

**Consideraciones de Rendimiento:**
- **Memoria RAM:** Los 2.1 GB de imÃ¡genes no se cargan todos a la vez. Procesamiento por lotes (batch processing).
- **NormalizaciÃ³n obligatoria:** Los valores de reflectancia satelital varÃ­an mucho entre bandas â†’ usar `StandardScaler` antes de PCA.
- **Dimensionalidad inicial:** Cada imagen es $(64 \times 64 \times 13) = 53,248$ caracterÃ­sticas por imagen.
- **Meta de PCA:** Reducir a ~50-200 componentes que capturen >90% de varianza.

---

### 4. Resultados Esperados del Proyecto

El proyecto debe culminar con un **Jupyter Notebook** (o informe en PDF) que incluya:

1. **Visualizaciones de calidad:**
   - GrÃ¡fico del Codo y Coeficiente de Silueta para K-Means
   - K-distance graph para DBSCAN
   - Matrices de ConfusiÃ³n (clÃºsteres vs. clases reales)
   - Montajes de imÃ¡genes representativas de cada clÃºster

2. **MÃ©tricas cuantitativas:**
   - Coeficiente de Silueta (K-Means y DBSCAN)
   - ARI y NMI (validaciÃ³n externa)
   - Porcentaje de varianza explicada por PCA

3. **InterpretaciÃ³n AgroecolÃ³gica:**
   - IdentificaciÃ³n clara de clÃºsteres que representan zonas en estrÃ©s
   - AnÃ¡lisis sobre la separabilidad de cultivos vs. bosques
   - Recomendaciones para la agencia de gestiÃ³n agrÃ­cola

---

### 5. PrÃ³ximos Pasos para Comenzar

**Paso Inmediato:** Comenzar con la **Fase 1 - IngenierÃ­a de Datos**

**Â¿Necesitas ayuda con:** 
- Â¿CÃ³digo para cargar las 13 bandas de las imÃ¡genes `.tif` de forma eficiente (Paso 1.1 y 1.2)?
- Â¿Script para aplanar, normalizar y aplicar PCA sin saturar la RAM (Pasos 1.3 a 1.6)?
- Â¿Estructura del cÃ³digo para procesar las 27,000 imÃ¡genes por lotes?

**RecomendaciÃ³n:** Trabaja primero con un subconjunto de ~1,000 imÃ¡genes para validar el pipeline completo antes de procesar las 27,000 imÃ¡genes.

---

### 6. Estructura del Informe Final

**Formato de Entrega:**
- **Informe en PDF:** MÃ¡ximo 25 pÃ¡ginas (incluyendo imÃ¡genes y tablas)
- **CÃ³digo:** Jupyter Notebook (.ipynb) o scripts de Python (.py)
- **Empaquetado:** Archivo ZIP conteniendo el informe PDF y todos los cÃ³digos ejecutables

**Secciones Recomendadas del Informe:**

1. **IntroducciÃ³n (1-2 pÃ¡ginas)**
   - Contexto del problema agroecolÃ³gico
   - DescripciÃ³n del dataset EuroSAT
   - Objetivos del proyecto

2. **MetodologÃ­a (3-4 pÃ¡ginas)**
   - Preprocesamiento y reducciÃ³n dimensional (PCA)
   - Algoritmos de clustering utilizados (K-Means y DBSCAN)
   - JustificaciÃ³n de hiperparÃ¡metros

3. **Resultados (10-12 pÃ¡ginas)**
   - **Fase 1:** Varianza explicada por PCA
   - **Fase 2:** GrÃ¡ficos del Codo y Silueta para K-Means
   - **Fase 3:** Resultados de DBSCAN y anÃ¡lisis de outliers
   - **Fase 4:** Matrices de confusiÃ³n, ARI, NMI
   - Incluir cÃ³digo relevante y bien comentado

4. **InterpretaciÃ³n AgroecolÃ³gica (4-6 pÃ¡ginas)**
   - CaracterizaciÃ³n de cada clÃºster
   - IdentificaciÃ³n de zonas en estrÃ©s
   - AnÃ¡lisis cultivos vs. bosques
   - Implicaciones para la agencia de gestiÃ³n agrÃ­cola

5. **Conclusiones y Recomendaciones (2-3 pÃ¡ginas)**
   - Efectividad del clustering no supervisado
   - Ventajas de usar datos multiespectrales (13 bandas)
   - Recomendaciones para intervenciones post-desastre

6. **Anexos**
   - CÃ³digo completo (si no estÃ¡ integrado en las secciones)
   - Tablas complementarias
   - ImÃ¡genes adicionales de clÃºsteres representativos

**âš ï¸ Recordatorio:** Siempre interpretar los resultados en el contexto agroecolÃ³gico, no solo reportar nÃºmeros.

---

### 7. Preguntas Clave a Responder en el Informe

Estas son las preguntas centrales derivadas del PDF que deben responderse:

1. **Sobre la reducciÃ³n dimensional:**
   - Â¿CuÃ¡ntos componentes de PCA se necesitaron para explicar >90% de la varianza?
   - Â¿QuÃ© porcentaje de reducciÃ³n dimensional se logrÃ³? ($53,248 \to m$)

2. **Sobre K-Means:**
   - Â¿CuÃ¡l es el nÃºmero Ã³ptimo de clÃºsteres $k$ segÃºn el mÃ©todo del codo y la Silueta?
   - Â¿El $k$ Ã³ptimo estÃ¡ en el rango esperado de 8-12?
   - Â¿QuÃ© clÃºsteres de K-Means representan zonas en estrÃ©s agroecolÃ³gico?

3. **Sobre DBSCAN:**
   - Â¿CÃ³mo se determinaron $\epsilon$ y `min_samples`?
   - Â¿CuÃ¡ntos clÃºsteres encontrÃ³ DBSCAN?
   - Â¿QuÃ© porcentaje de imÃ¡genes fueron clasificadas como ruido/anomalÃ­as (`-1`)?
   - Â¿Estas anomalÃ­as corresponden a nubes, errores de sensor o coberturas anÃ³malas?

4. **Sobre la validaciÃ³n:**
   - Â¿QuÃ© algoritmo tuvo mejor Coeficiente de Silueta?
   - Â¿QuÃ© algoritmo tuvo mayor ARI y NMI al comparar con las etiquetas reales?
   - Â¿La validaciÃ³n externa confirma la calidad del clustering no supervisado?

5. **Sobre la interpretaciÃ³n agroecolÃ³gica:**
   - Â¿QuÃ© clÃºsteres corresponden a "suelo desnudo", "zona industrial" y "agua estancada"?
   - Â¿Se separaron claramente los **Cultivos** de los **Bosques**?
   - Â¿QuÃ© proporciÃ³n del territorio estÃ¡ en estado saludable vs. en estrÃ©s?
   - Â¿El enfoque multiespectral (13 bandas) fue ventajoso vs. imÃ¡genes RGB tradicionales?

---

### 8. Referencias y Recursos Adicionales

**Dataset:**
- EuroSAT: [https://github.com/phelber/eurosat](https://github.com/phelber/eurosat)
- Paper: *EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification* (Helber et al., 2019)

**DocumentaciÃ³n TÃ©cnica:**
- Sentinel-2 Bands: [ESA Sentinel-2 User Guide](https://sentinels.copernicus.eu/web/sentinel/user-guides/sentinel-2-msi)
- Scikit-learn Clustering: [https://scikit-learn.org/stable/modules/clustering.html](https://scikit-learn.org/stable/modules/clustering.html)

**MÃ©tricas de EvaluaciÃ³n:**
- Adjusted Rand Index (ARI): Mide similitud entre particiones ajustando por azar
- Normalized Mutual Information (NMI): Cuantifica informaciÃ³n compartida entre agrupaciones
- Silhouette Coefficient: EvalÃºa cohesiÃ³n intra-cluster y separaciÃ³n inter-cluster

**Conceptos Clave:**
- **Clustering No Supervisado:** AgrupaciÃ³n sin etiquetas previas, ideal para escenarios post-desastre
- **PCA para datos espectrales:** ReducciÃ³n dimensional extrayendo patrones dominantes de reflectancia
- **13 Bandas de Sentinel-2:** Incluyen infrarrojo cercano (NIR) e infrarrojo de onda corta (SWIR), crÃ­ticos para diferenciar vegetaciÃ³n saludable de suelo desnudo

---

## âœ… Checklist de Completitud del Proyecto

Usa esta lista para verificar que has completado todos los elementos requeridos:

- [ ] **Fase 1 completada:** Datos reducidos con PCA guardados en `data_processed/`
- [ ] **Fase 2 completada:** K-Means ejecutado con grÃ¡ficos del Codo y Silueta
- [ ] **Fase 3 completada:** DBSCAN con justificaciÃ³n de hiperparÃ¡metros
- [ ] **Fase 4 completada:** Matrices de confusiÃ³n, ARI y NMI calculados
- [ ] **Fase 5 completada:** InterpretaciÃ³n agroecolÃ³gica documentada
- [ ] **CÃ³digo limpio y comentado:** Jupyter Notebook funcional
- [ ] **Visualizaciones de calidad:** Todas las figuras exportadas en `outputs/figures/`
- [ ] **Informe PDF:** MÃ¡ximo 25 pÃ¡ginas con interpretaciones contextualizadas
- [ ] **Empaquetado:** Archivo ZIP con informe + cÃ³digo listo para entrega
- [ ] **RevisiÃ³n final:** Todas las preguntas clave respondidas

---

## ğŸ“‹ Criterios de EvaluaciÃ³n

**SituaciÃ³n 2 vale 0.75 puntos del Proyecto 1. Aspectos a evaluar:**

### 1. MetodologÃ­a TÃ©cnica (30%)
- **ReducciÃ³n dimensional apropiada:** PCA correctamente aplicado con normalizaciÃ³n previa
- **SelecciÃ³n de algoritmos:** JustificaciÃ³n de uso de K-Means y DBSCAN
- **OptimizaciÃ³n de hiperparÃ¡metros:** Proceso documentado para elegir $k$, $\epsilon$ y `min_samples`

### 2. ImplementaciÃ³n y CÃ³digo (25%)
- **CÃ³digo funcional:** Jupyter Notebook ejecutable sin errores
- **Eficiencia:** Manejo adecuado de grandes volÃºmenes de datos (2.1 GB)
- **Reproducibilidad:** Datos procesados guardados, modelos persistidos
- **DocumentaciÃ³n:** CÃ³digo bien comentado y organizado

### 3. AnÃ¡lisis y Visualizaciones (25%)
- **GrÃ¡ficos obligatorios:** Codo, Silueta, Matriz de ConfusiÃ³n
- **Calidad visual:** GrÃ¡ficos profesionales con tÃ­tulos, ejes etiquetados, leyendas
- **MÃ©tricas cuantitativas:** ARI, NMI, Coeficiente de Silueta reportados correctamente

### 4. InterpretaciÃ³n Contextual (20%)
- **Enfoque agroecolÃ³gico:** InterpretaciÃ³n de clÃºsteres en tÃ©rminos de cobertura terrestre
- **IdentificaciÃ³n de zonas en estrÃ©s:** Respuesta clara a la pregunta del proyecto
- **Conclusiones fundamentadas:** Hallazgos respaldados por evidencia cuantitativa

---

## ğŸ’¡ Mejores PrÃ¡cticas y Recomendaciones

### Para la Fase 1 (Procesamiento):
- âœ… **Trabajar primero con un subset pequeÃ±o** (~1,000 imÃ¡genes) para validar el pipeline
- âœ… Verificar que todas las imÃ¡genes tienen las mismas dimensiones (64Ã—64Ã—13)
- âœ… Documentar el tiempo de procesamiento de cada fase
- âŒ No cargar las 27,000 imÃ¡genes en RAM simultÃ¡neamente

### Para las Fases 2-3 (Clustering):
- âœ… Probar mÃºltiples valores de $k$ (no solo uno)
- âœ… Visualizar clÃºsteres en el espacio PCA (primeros 2-3 componentes)
- âœ… Guardar los modelos entrenados para reproducibilidad
- âŒ No aplicar clustering sobre datos sin normalizar

### Para la Fase 4 (EvaluaciÃ³n):
- âœ… Generar matrices de confusiÃ³n normalizadas (porcentajes)
- âœ… Calcular todas las mÃ©tricas (Silueta, ARI, NMI) para ambos modelos
- âœ… Comparar resultados de forma objetiva con tabla resumen
- âŒ No confundir validaciÃ³n interna (Silueta) con externa (ARI, NMI)

### Para el Informe:
- âœ… Incluir cÃ³digo relevante directamente en el informe (no solo en anexo)
- âœ… Cada grÃ¡fico debe tener un anÃ¡lisis textual asociado
- âœ… Usar terminologÃ­a tÃ©cnica correcta (clÃºster, dimensionalidad, reflectancia espectral)
- âŒ No exceder las 25 pÃ¡ginas
- âŒ No solo reportar nÃºmeros sin interpretaciÃ³n contextual

---

## ğŸš€ Â¿Listo para Comenzar?

**Siguiente acciÃ³n inmediata:**  
Comenzar con la **Fase 1, Paso 1.1** - Carga eficiente de las imÃ¡genes `.tif`

**Â¿Necesitas soporte de cÃ³digo?** Pregunta por ayuda especÃ­fica en cualquier paso del plan.