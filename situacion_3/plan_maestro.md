# Plan Maestro â€” SituaciÃ³n 3: AnÃ¡lisis de Portafolio Hipotecario a Gran Escala

**Proyecto:** AnalÃ­tica de Datos I â€” Proyecto 1, SituaciÃ³n 3  
**Dataset:** Freddie Mac Single-Family Fixed-Rate Loan Performance Data  
**Autor:** NicolÃ¡s Zapata Obando  
**Fecha:** Febrero 2026

---

## 1. Resumen del Problema

Se requiere procesar y analizar el dataset **Freddie Mac Single-Family Fixed-Rate Loan Performance**, compuesto por **101 archivos CSV** dentro de un Ãºnico archivo comprimido (`Performance.zip`, 55.31 GB comprimido, **~820 GB descomprimido**). Cada archivo corresponde a un trimestre (2000Q1 â†’ 2025Q1) y contiene datos mensuales de desempeÃ±o de prÃ©stamos hipotecarios. Los archivos individuales varÃ­an entre 0.11 GB y 37.20 GB descomprimidos, con 110 columnas separadas por `|` y **sin fila de encabezados**.

### Restricciones TÃ©cnicas CrÃ­ticas

| RestricciÃ³n | Detalle |
|:---|:---|
| **RAM combinada** | ~30 GB efectivos (PortÃ¡til 19 GB + Servidor 14 GB - overhead SO) |
| **Archivo mÃ¡s grande** | 2003Q3.csv â†’ 37.20 GB descomprimido (no cabe en RAM de ninguna mÃ¡quina) |
| **Total descomprimido** | ~820 GB (imposible mantener todo en memoria) |
| **Sin GPU CUDA** | 100% procesamiento por CPU â†’ se necesita paralelizaciÃ³n |
| **Datos en disco remoto** | Dataset alojado en HDD 1TB del servidor, acceso vÃ­a NFS sobre Wi-Fi |
| **Latencia de red** | Wi-Fi introduce delay; se requieren barras de progreso y buffering |

---

## 2. Arquitectura del ClÃºster Distribuido

### 2.1 TopologÃ­a: Master-Worker sobre LAN

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       LAN (Wi-Fi / Ethernet)       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     PORTÃTIL (Master Node)       â”‚â—„â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â–ºâ”‚    PC DE MESA (Worker Node)      â”‚
â”‚  Ubuntu 24.04 Desktop            â”‚                                     â”‚  Ubuntu 24.04 Server             â”‚
â”‚  Intel i5-1155G7 (4C/8T)         â”‚           Ray Cluster               â”‚  AMD Athlon 3000G (2C/4T)        â”‚
â”‚  19 GB RAM                       â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  14 GB RAM                       â”‚
â”‚  IP: 192.168.1.17                â”‚                                     â”‚  IP: 192.168.1.15                â”‚
â”‚  NVMe 238 GB                     â”‚         NFS (puerto 2049)           â”‚  HDD 1TB (Dataset 55 GB ZIP)     â”‚
â”‚                                  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  SSD 256 GB (SO)                 â”‚
â”‚  â†’ Coordina tareas Ray           â”‚         SSH (puerto 22)             â”‚  â†’ Servidor de datos NFS         â”‚
â”‚  â†’ Procesa archivos GRANDES      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  â†’ Procesa archivos PEQUEÃ‘OS     â”‚
â”‚  â†’ Agrega resultados finales     â”‚                                     â”‚  â†’ Libera memoria al acabar      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                                                                    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Recursos Combinados â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    12 hilos CPU | ~30 GB RAM efectiva
```

### 2.2 Roles Fijos (Sin CoordinaciÃ³n DinÃ¡mica)

| Propiedad | PortÃ¡til (Master) | Servidor (Worker) |
|:---|:---|:---|
| **CPU** | 8 hilos (i5-1155G7) | 4 hilos (Athlon 3000G) |
| **RAM total** | 19 GB | 14 GB |
| **RAM para datos** | ~4.5 GB por chunk (25% de 19 GB) | ~3 GB por chunk (25% de 13 GB) |
| **Chunk size** | 750,000 filas | 500,000 filas |
| **Chunk size (archivos >20 GB)** | 375,000 filas | 250,000 filas |
| **Archivos asignados** | ~37 archivos GRANDES (>10 GB) | ~64 archivos PEQUEÃ‘OS y MEDIANOS |
| **Rol primario** | Procesador principal + agregaciÃ³n | Procesador secundario |
| **Escritura Parquet** | A disco compartido NFS | A disco compartido NFS |

La lista de 101 archivos se divide **estÃ¡ticamente al inicio**: el Master toma los archivos pesados, el Worker toma los mÃ¡s ligeros. No hay coordinaciÃ³n dinÃ¡mica entre mÃ¡quinas â€” cada una trabaja su lista de manera independiente para evitar complejidad.

### 2.3 Framework de DistribuciÃ³n: Ray

Se utiliza **Ray** como framework de computaciÃ³n distribuida:

1. **DistribuciÃ³n automÃ¡tica de memoria:** Objetos en Object Store compartido sin duplicar datos
2. **Scheduling inteligente:** Asigna tareas al nodo con mÃ¡s recursos disponibles
3. **Tolerancia a fallos:** Reintento automÃ¡tico de tareas fallidas por red
4. **API PythÃ³nica:** Se integra con pandas, numpy y scikit-learn

```bash
# Iniciar clÃºster (usar scripts/ray_start.sh):
# En el Servidor (Worker):
ray start --address='192.168.1.17:6379' --num-cpus=4

# En el PortÃ¡til (Master):
ray start --head --port=6379 --num-cpus=8
```

### 2.4 CoordinaciÃ³n entre MÃ¡quinas

El esquema de coordinaciÃ³n es un **archivo de estado compartido en JSON** en el directorio NFS:

```
data_processed/.checkpoints/processing_state.json
```

Cada mÃ¡quina escribe el estado de cada archivo:
- `PENDIENTE` â†’ no iniciado
- `EN_PROCESO` â†’ una mÃ¡quina lo tiene
- `COMPLETADO` â†’ Parquet escrito y validado
- `ERROR` â†’ fallÃ³, requiere reprocesamiento

Antes de empezar un archivo, la mÃ¡quina verifica que no estÃ© `EN_PROCESO` en la otra.

---

## 3. Estructura de Directorios

```
situacion_3/
â”‚
â”œâ”€â”€ plan_maestro.md                    â† Este archivo
â”œâ”€â”€ README.md                          â† Inicio rÃ¡pido
â”œâ”€â”€ requirements.txt                   â† Dependencias
â”œâ”€â”€ run_pipeline.py                    â† Ejecutor principal del pipeline
â”œâ”€â”€ .gitignore                         â† Excluir datos pesados
â”‚
â”œâ”€â”€ scripts/                           â† Scripts de ejecuciÃ³n rÃ¡pida
â”‚   â”œâ”€â”€ info_cluster.sh               â† Info CPU/RAM de ambas mÃ¡quinas
â”‚   â”œâ”€â”€ monitor_cluster.sh            â† Monitor en tiempo real
â”‚   â”œâ”€â”€ ray_start.sh                  â† Iniciar/detener clÃºster Ray
â”‚   â””â”€â”€ test_parallelization.sh       â† Verificar que Ray funciona
â”‚
â”œâ”€â”€ docs/                              â† DocumentaciÃ³n tÃ©cnica
â”‚   â”œâ”€â”€ red/                           â† Scripts de red y SSH
â”‚   â”‚   â”œâ”€â”€ .config_red.sh            â† Credenciales SSH (no subir a git)
â”‚   â”‚   â”œâ”€â”€ ssh_rapido.sh             â† SSH al servidor sin contraseÃ±a
â”‚   â”‚   â”œâ”€â”€ verificar_red.sh          â† DiagnÃ³stico de red completo
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ paralelizacion/               â† Doc de la instalaciÃ³n del clÃºster
â”‚       â””â”€â”€ documentacion_paralelizacion.md
â”‚
â”œâ”€â”€ dataset/                           â† Datos crudos (NO subir a git)
â”‚   â””â”€â”€ Performance.zip                â† 55.31 GB comprimido (101 CSVs)
â”‚
â”œâ”€â”€ data_processed/                    â† Datos intermedios procesados
â”‚   â”œâ”€â”€ panel_analitico/               â† Archivos Parquet convertidos
â”‚   â”‚   â”œâ”€â”€ 2000Q1.parquet
â”‚   â”‚   â”œâ”€â”€ 2000Q2.parquet
â”‚   â”‚   â””â”€â”€ ... (101 archivos)
â”‚   â”œâ”€â”€ perfiles/                      â† Perfiles estadÃ­sticos JSON
â”‚   â”‚   â”œâ”€â”€ perfil_2000Q1.json
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ perfil_global.json             â† Perfil consolidado de 110 columnas
â”‚   â”œâ”€â”€ features_latentes/             â† Scores factoriales / embeddings
â”‚   â”œâ”€â”€ .checkpoints/                  â† Estado del procesamiento
â”‚   â”‚   â””â”€â”€ processing_state.json
â”‚   â””â”€â”€ processing_log.txt
â”‚
â”œâ”€â”€ src/                               â† CÃ³digo fuente del pipeline
â”‚   â”œâ”€â”€ config.py                      â† Variables globales, rutas, parÃ¡metros
â”‚   â”œâ”€â”€ 00_test_headers.py             â† Fase 0.0: Verificar estructura
â”‚   â”œâ”€â”€ 01_construccion_panel.py       â† Fase 0: EDA + ConversiÃ³n a Parquet
â”‚   â”œâ”€â”€ 02_analisis_latente.py         â† Fase 1: AFE/AFC + reducciÃ³n dimensional
â”‚   â”œâ”€â”€ 03_deep_learning.py            â† Fase 2: VAE para embeddings
â”‚   â”œâ”€â”€ 04_clustering.py               â† Fase 3: K-Means, GMM, jerÃ¡rquico
â”‚   â”œâ”€â”€ 05_perfilado_riesgo.py         â† Fase 4: Perfiles de riesgo
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data_loader.py             â† Carga distribuida desde ZIP
â”‚       â”œâ”€â”€ memory_utils.py            â† Monitoreo y liberaciÃ³n de RAM
â”‚       â””â”€â”€ plotting_utils.py          â† GrÃ¡ficos acadÃ©micos (300 DPI)
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ figures/
â”‚   â”‚   â”œâ”€â”€ 00_exploratorio/           â† Histogramas, nulidad, distribuciones
â”‚   â”‚   â”œâ”€â”€ 01_panel/
â”‚   â”‚   â”œâ”€â”€ 02_latente/
â”‚   â”‚   â”œâ”€â”€ 03_deep_learning/
â”‚   â”‚   â”œâ”€â”€ 04_clustering/
â”‚   â”‚   â””â”€â”€ 05_perfiles/
â”‚   â”œâ”€â”€ models/                        â† Modelos (.pkl, .pt)
â”‚   â”œâ”€â”€ tables/                        â† Tablas CSV
â”‚   â””â”€â”€ reports/
â”‚
â””â”€â”€ notebooks/
    â””â”€â”€ situacion_3.ipynb
```

---

## 4. EspecificaciÃ³n del Dataset

### 4.1 Inventario del ZIP

| Propiedad | Valor |
|:---|:---|
| **Archivo** | `Performance.zip` |
| **Comprimido** | 55.31 GB |
| **Descomprimido** | ~820 GB |
| **Archivos internos** | 101 (2000Q1 a 2025Q1) |
| **Formato** | CSV delimitado por `\|` (pipe), SIN encabezados |
| **Columnas** | 110 (primera vacÃ­a por `\|` inicial) |
| **MÃ¡s pequeÃ±o** | `2025Q1.csv` â†’ 0.11 GB |
| **MÃ¡s grande** | `2003Q3.csv` â†’ 37.20 GB |

### 4.2 ClasificaciÃ³n de Archivos por TamaÃ±o

| CategorÃ­a | Rango | Archivos aprox. | Chunk size | MÃ¡quina asignada |
|:---|:---|:---|:---|:---|
| **PequeÃ±o** | < 2 GB | ~5 | Carga directa | Worker |
| **Mediano** | 2 â€“ 10 GB | ~55 | 500K filas | Worker |
| **Grande** | > 10 GB | ~41 | 250K filas | Master |

### 4.3 Encabezados

Los 110 nombres de columna se definen en `config.py â†’ PERFORMANCE_COLUMNS`. Incluyen:

| Rango | DescripciÃ³n |
|:---|:---|
| 1-5 | IdentificaciÃ³n del prÃ©stamo y servicer |
| 6-9 | Tasas de interÃ©s y saldos |
| 10-18 | Plazos, fechas, madurez |
| 19-24 | LTV, DTI, FICO (variables clave de riesgo) |
| 25-35 | Tipo de propiedad, propÃ³sito, ocupaciÃ³n |
| 36-60 | Modificaciones, costos de disposiciÃ³n, ejecuciÃ³n |
| 61-109 | Campos extendidos Freddie Mac 2024 |

---

## 5. Â¿Por quÃ© convertir a Parquet? â€” ComparaciÃ³n real

| MÃ©trica | CSV descomprimido | Parquet (Snappy) | Parquet (Zstd) |
|:---|:---|:---|:---|
| **TamaÃ±o estimado** | 819 GB | 90â€“130 GB | 70â€“100 GB |
| **Leer 10 columnas de 110** | Lee 819 GB | Lee ~75 GB | Lee ~64 GB |
| **Filtrar por aÃ±o** | Recorre todo | Salta particiones | Salta particiones |
| **Schema / tipos** | Inferido cada vez | Guardado | Guardado |
| **Velocidad de lectura** | 1x | 8â€“15x | 10â€“20x |
| **CompresiÃ³n vs ZIP** | 1.46x mÃ¡s grande | Similar al ZIP | MÃ¡s pequeÃ±o que ZIP |

**Punto clave:** Con lectura columnar, si una consulta necesita 15 de las 110 columnas, Parquet lee fÃ­sicamente solo esas 15. El CSV lee las 819 GB completas. Con RAM limitada (19 y 13 GB), esto es la diferencia entre que el script funcione o que congele la mÃ¡quina.

---

## 6. Fase 0: ConstrucciÃ³n del Panel AnalÃ­tico â€” EDA Masivo desde ZIP

Esta fase es la mÃ¡s crÃ­tica del pipeline. Hace **dos cosas simultÃ¡neamente** para no leer los 819 GB dos veces:
1. **Convierte los 101 CSVs a Parquet** (comprimido, columnar)
2. **Acumula estadÃ­sticas del EDA** por cada archivo y columna

### 6.1 Estrategia de ExtracciÃ³n desde el ZIP â€” Sin Descomprimir

La librerÃ­a `zipfile` de Python permite leer archivos individuales del ZIP sin extraer el resto. **Nunca se extraen los 819 GB al disco.**

```
Performance.zip (55.31 GB en disco)
    â”‚
    â”œâ”€â”€ Leer metadatos del ZIP (tabla de contenidos, tamaÃ±os, CRC32)
    â”‚
    â”œâ”€â”€ Por cada archivo en la lista asignada a esta mÃ¡quina:
    â”‚   â”œâ”€â”€ Abrir stream del CSV dentro del ZIP (sin extraer)
    â”‚   â”œâ”€â”€ Leer en chunks de N filas
    â”‚   â”œâ”€â”€ Procesar chunk â†’ acumular estadÃ­sticas
    â”‚   â”œâ”€â”€ Escribir chunk a Parquet (append)
    â”‚   â”œâ”€â”€ Liberar memoria del chunk explÃ­citamente
    â”‚   â””â”€â”€ Al terminar â†’ cerrar stream â†’ gc.collect()
    â”‚
    â””â”€â”€ Archivo Parquet resultante queda en disco
```

### 6.2 Criterio para el TamaÃ±o del Chunk

Con 19 GB de RAM en el Master, el chunk debe ocupar mÃ¡ximo el **25% de la RAM disponible** para dejar espacio al proceso de escritura y a las estadÃ­sticas acumuladas.

Para las 110 columnas de tipo mixto, una fila pesa aproximadamente **500-800 bytes** en memoria como DataFrame:

| MÃ¡quina | RAM disponible para chunk | Bytes por fila | Chunk size |
|:---|:---|:---|:---|
| **Master (19 GB)** | 4.5 GB (25%) | ~600 bytes | ~750,000 filas |
| **Worker (14 GB)** | 3 GB (25%) | ~600 bytes | ~500,000 filas |

Para archivos marcados como **grandes** (>20 GB descomprimidos, como 2003Q3 o 2020-2021), el chunk se reduce a la mitad automÃ¡ticamente: ~375,000 filas en Master.

---

### 6.3 Sub-Fase 0.1 â€” Inventario del ZIP

> **Script:** `00_test_headers.py` (ya ejecutado âœ…)  
> **Memoria:** < 50 MB  
> **Tiempo:** ~30 segundos

Lee la tabla de contenidos del ZIP sin extraer nada:
- Nombre de cada archivo dentro del ZIP
- TamaÃ±o comprimido y descomprimido
- CRC32 de cada archivo (para verificar integridad despuÃ©s)
- VerificaciÃ³n de las 110 columnas en cada archivo

**Output:** `file_inventory.csv`, `column_consistency_check.csv`, `file_sizes_inventory.png`

---

### 6.4 Sub-Fase 0.2 â€” ConversiÃ³n a Parquet + Perfilado SimultÃ¡neo

> **Script:** `01_construccion_panel.py`  
> **Tiempo estimado:** 9-15 horas (paralelo, no supervisado)

Este es el script central. Procesa cada archivo CSV en esta secuencia:

#### Bloque 1 â€” InicializaciÃ³n por archivo

1. Abrir stream del CSV dentro del ZIP
2. Leer primeras 5 filas para detectar el schema real
3. Inicializar el acumulador de estadÃ­sticas (un dict por columna)
4. Inicializar el writer de Parquet en modo append

#### Bloque 2 â€” Loop de chunks

Por cada chunk leÃ­do:

**Paso 1 â€” Limpieza de valores centinela:**
Reemplazar valores centinela de Freddie Mac (`9`, `99`, `999`, `9999` segÃºn el campo) por `NaN` real. Sin esta limpieza, la media de FICO con los 9999 de missing sale disparada.

**Paso 2 â€” Inferencia de tipos por columna:**
Freddie Mac reporta columnas numÃ©ricas como string porque mezclan valores como `"XX"` para missing. Se detecta quÃ© columnas son numÃ©ricas, categÃ³ricas y fechas. El mapeo se guarda una sola vez en el primer chunk.

**Paso 3 â€” AcumulaciÃ³n de estadÃ­sticas:**
- **NumÃ©ricas:** n vÃ¡lidos, n nulos, suma, suma de cuadrados, mÃ­nimo, mÃ¡ximo, histograma de 200 bins (bins fijados en primer chunk)
- **CategÃ³ricas:** Counter de frecuencias (top-500 categorÃ­as mÃ¡s frecuentes)

**Paso 4 â€” Escritura a Parquet:**
El chunk con tipos correctos se escribe al Parquet con compresiÃ³n **Zstd nivel 3** (balance compresiÃ³n/velocidad). Si el archivo descomprimido supera 5 GB, se divide en mÃºltiples Parquet de mÃ¡ximo 2 GB.

**Paso 5 â€” LiberaciÃ³n de memoria:**
Se eliminan todas las variables del chunk, se llama `gc.collect()`, y se verifica con `psutil` que la memoria volviÃ³ al nivel base. Si detecta leak, reduce el chunk size automÃ¡ticamente.

#### Bloque 3 â€” Cierre del archivo

1. Cerrar writer de Parquet
2. Calcular estadÃ­sticas finales: media = suma/n, varianza = (sumaÂ²/n) - mediaÂ²
3. Guardar perfil como JSON: `perfil_2003Q1.json`
4. Registrar en log: nombre, tiempo, filas totales, columnas con >5% nulos
5. `gc.collect()` final

---

### 6.5 Sub-Fase 0.3 â€” ValidaciÃ³n de Integridad Post-ConversiÃ³n

DespuÃ©s de convertir cada archivo, un script de validaciÃ³n verifica:

1. **Row count:** Parquet vs log de conversiÃ³n (deben ser idÃ©nticos)
2. **Rango de valores:** Ninguna columna numÃ©rica fuera del rango observado
3. **Schema:** El Parquet coincide con el schema target
4. **CRC:** Registro de integridad futura

Si falla â†’ marca como `REQUIERE_REPROCESAMIENTO` y reintenta solo ese archivo.

---

### 6.6 Sub-Fase 0.4 â€” ConsolidaciÃ³n del Perfil EstadÃ­stico Global

Una vez que ambas mÃ¡quinas terminan, se consolidan los 101 perfiles JSON individuales:

**Outputs:**

1. **Tabla maestra de perfil de columnas:** 110 filas Ã— ~30 columnas de estadÃ­sticas. Input del EDA visual y decisiones de ingenierÃ­a de features.

2. **Reporte de evoluciÃ³n temporal:** Para las 20 columnas clave (FICO, LTV, DTI, tasa, monto, estado de pago), una tabla donde cada fila es un trimestre y las columnas son estadÃ­sticas. Revela cambios estructurales sin visualizaciÃ³n.

3. **Mapa de nulidad:** Matriz de 101 trimestres Ã— 110 columnas con el % de nulos en cada celda. Visible si hay columnas que se vuelven nulas en ciertos perÃ­odos.

4. **Ranking de columnas por informatividad:** Ordenadas por entropÃ­a (categÃ³ricas) o coeficiente de variaciÃ³n (numÃ©ricas). Columnas con entropÃ­a ~0 o variaciÃ³n <1% â†’ candidatas a eliminaciÃ³n antes del AFE.

---

### 6.7 EstimaciÃ³n de Tiempos

| Etapa | Master (PortÃ¡til) | Worker (Servidor) |
|:---|:---|:---|
| Inventario del ZIP | 30s âœ… | â€” |
| ConversiÃ³n + perfilado | 8-14 horas | 5-9 horas |
| ValidaciÃ³n post-conversiÃ³n | 30-60 min | 20-40 min |
| ConsolidaciÃ³n global | 10-20 min | â€” |

**Tiempo total en paralelo:** ~9-15 horas de procesamiento no supervisado.

Por eso el **checkpoint por archivo** es crÃ­tico: si la mÃ¡quina se congela a las 7 horas, el script retoma desde el Ãºltimo archivo completado, no desde cero.

### 6.8 Output Final de la Fase 0

Al terminar:
- 101 archivos Parquet (estimado 70-100 GB total)
- Perfil estadÃ­stico completo de las 110 columnas
- Log de integridad de cada archivo
- Matriz de nulidad temporal
- Ranking de informatividad de columnas

Con esto, las fases posteriores trabajan sobre Parquet en **minutos** en lugar de horas, y nunca mÃ¡s tocan el ZIP original salvo para re-validar.

---

## 7. Fases del Pipeline AnalÃ­tico

### Fase 1: ExtracciÃ³n de Componentes Latentes
**Script:** `02_analisis_latente.py`
- AFE (AnÃ¡lisis Factorial Exploratorio) sobre variables numÃ©ricas del panel
- AFC (AnÃ¡lisis Factorial Confirmatorio) para validar hipÃ³tesis de riesgo
- ReducciÃ³n dimensional con PCA/Factor Analysis para datos mixtos
- Generar matriz de puntuaciones factoriales

### Fase 2: Deep Learning â€” Autoencoders
**Script:** `03_deep_learning.py`
- VAE (Variational Autoencoder) para representaciÃ³n no lineal
- Entrenamiento distribuido entre Master y Worker con Ray
- Generar embeddings de riesgo de baja dimensiÃ³n

### Fase 3: SegmentaciÃ³n (Clustering)
**Script:** `04_clustering.py`
- K-Means sobre scores/embeddings latentes
- Gaussian Mixture Models (GMM)
- Clustering jerÃ¡rquico (Ward)
- ComparaciÃ³n de mÃ©tricas (Silhouette, Davies-Bouldin, Calinski-Harabasz)

### Fase 4: CaracterizaciÃ³n de Perfiles de Riesgo
**Script:** `05_perfilado_riesgo.py`
- Centroides por cluster
- Perfilado financiero: FICO, LTV, DTI, tasa de morosidad
- VisualizaciÃ³n de perfiles con grÃ¡ficos de radar
- GeneraciÃ³n de informe final

---

## 8. ParÃ¡metros de Procesamiento

### 8.1 ParÃ¡metros de Memoria

| ParÃ¡metro | Valor | DescripciÃ³n |
|:---|:---|:---|
| `CHUNK_THRESHOLD_GB` | 2.0 | Si archivo > 2 GB â†’ modo chunked |
| `CHUNK_SIZE_ROWS` | 500,000 | Filas por chunk (medianos) |
| `CHUNK_SIZE_ROWS_LARGE` | 250,000 | Filas por chunk (>10 GB) |
| `MIN_AVAILABLE_RAM_GB` | 3.0 | Pausar si RAM disponible < 3 GB |
| `MEMORY_WARNING_THRESHOLD` | 80% | Advertencia |
| `MEMORY_CRITICAL_THRESHOLD` | 90% | Pausa forzada |

### 8.2 ParÃ¡metros de Red

| ParÃ¡metro | Valor | DescripciÃ³n |
|:---|:---|:---|
| `NFS_MOUNT_POINT` | `/mnt/datasets/` | Punto de montaje NFS |
| `NETWORK_TIMEOUT_SECONDS` | 120 | Timeout para lectura |
| `NETWORK_RETRY_ATTEMPTS` | 3 | Reintentos ante fallo |
| `NETWORK_RETRY_DELAY` | 5 | Segundos entre reintentos |

### 8.3 ParÃ¡metros de Ray

| ParÃ¡metro | Valor | DescripciÃ³n |
|:---|:---|:---|
| `RAY_MASTER_IP` | `192.168.1.17` | IP del portÃ¡til |
| `RAY_WORKER_IP` | `192.168.1.15` | IP del servidor |
| `RAY_HEAD_PORT` | 6379 | Puerto Ray |
| `RAY_MASTER_CPUS` | 8 | CPUs Master |
| `RAY_WORKER_CPUS` | 4 | CPUs Worker |
| `RAY_OBJECT_STORE_MB` | 4000 | Object Store (~4 GB) |

### 8.4 ParÃ¡metros de Parquet

| ParÃ¡metro | Valor | DescripciÃ³n |
|:---|:---|:---|
| `PARQUET_COMPRESSION` | `zstd` | CompresiÃ³n (mejor ratio que snappy) |
| `PARQUET_COMPRESSION_LEVEL` | 3 | Nivel Zstd (balance velocidad/ratio) |
| `PARQUET_MAX_FILE_SIZE_GB` | 2.0 | Dividir si Parquet > 2 GB |
| `PARQUET_ROW_GROUP_SIZE` | 500,000 | Filas por row group |

### 8.5 ParÃ¡metros de Modelos

| ParÃ¡metro | Valor | DescripciÃ³n |
|:---|:---|:---|
| `PCA_VARIANCE_THRESHOLD` | 0.90 | Retener 90% varianza |
| `N_FACTORS_RANGE` | (5, 30) | Factores para AFE |
| `KMEANS_K_RANGE` | range(3, 15) | Valores de K |
| `GMM_N_COMPONENTS_RANGE` | range(3, 15) | Componentes GMM |
| `VAE_LATENT_DIM` | 32 | DimensiÃ³n espacio latente |
| `VAE_EPOCHS` | 50 | Ã‰pocas de entrenamiento |
| `VAE_BATCH_SIZE` | 1024 | Batch size |
| `RANDOM_STATE` | 42 | Semilla reproducible |

---

## 9. Valores Centinela de Freddie Mac

Freddie Mac usa valores especÃ­ficos para indicar datos faltantes. Deben reemplazarse por `NaN` antes de calcular estadÃ­sticas:

| Campo | Valor centinela | Significado |
|:---|:---|:---|
| `borrower_credit_score` | 9999 | FICO no disponible |
| `co_borrower_credit_score` | 9999 | FICO co-prestatario no disponible |
| `original_dti` | 999 | DTI no disponible |
| `original_ltv` | 999 | LTV no disponible |
| `original_cltv` | 999 | CLTV no disponible |
| `mortgage_insurance_pct` | 999 | MI% no disponible |
| `number_of_borrowers` | 99 | No disponible |
| `current_loan_delinquency_status` | `"XX"` | No reportado |
| Campos genÃ©ricos string | `""`, `" "` | VacÃ­o |

---

## 10. GestiÃ³n de la Latencia de Red (Wi-Fi / NFS)

### 10.1 Velocidad estimada

| Escenario | Velocidad | Tiempo para 37 GB |
|:---|:---|:---|
| Wi-Fi 5 (mejor caso) | 100 MB/s | ~6 min |
| Wi-Fi (caso tÃ­pico) | 40 MB/s | ~15 min |
| Wi-Fi (peor caso) | 20 MB/s | ~31 min |

### 10.2 Barras de progreso

```
ğŸ“ Leyendo 2003Q3.csv (37.20 GB descomprimido)...
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 65% | Chunk 10/74 | 42 MB/s | ETA: 5:12
ğŸ’¾ RAM: 12.3/19.0 GB (65%) | Disponible: 6.7 GB
```

### 10.3 Reintentos automÃ¡ticos

3 intentos con 5 segundos entre cada uno ante fallos de `IOError` o `TimeoutError`.

---

## 11. Convenciones de CÃ³digo

1. **Cada script es autosuficiente** â€” ejecutable individualmente o como pipeline
2. **Importaciones desde config** â€” nunca hardcodear rutas o constantes
3. **LiberaciÃ³n de memoria** â€” `del variable` + `gc.collect()` despuÃ©s de usar
4. **Logging** â€” timestamps, uso de RAM y progreso al iniciar/finalizar
5. **Barras de progreso** â€” `tqdm` en toda operaciÃ³n >5 segundos
6. **Docstrings en espaÃ±ol** â€” cada funciÃ³n documentada
7. **Type hints** â€” en todas las funciones
8. **Formato Parquet** â€” datos intermedios en Parquet (no CSV)
9. **Figuras a 300 DPI** â€” vÃ­a `plotting_utils.save_figure()`
10. **Checkpoint por archivo** â€” poder retomar si falla

---

## 12. Scripts de EjecuciÃ³n RÃ¡pida

| Script | FunciÃ³n | Uso |
|:---|:---|:---|
| `scripts/info_cluster.sh` | Info CPU/RAM/Ray de ambas mÃ¡quinas | `bash scripts/info_cluster.sh` |
| `scripts/monitor_cluster.sh` | Monitor en tiempo real (cada 3s) | `bash scripts/monitor_cluster.sh [intervalo]` |
| `scripts/ray_start.sh` | Iniciar/detener clÃºster Ray | `bash scripts/ray_start.sh {all\|stop\|status}` |
| `scripts/test_parallelization.sh` | Test funcional de Ray | `bash scripts/test_parallelization.sh` |
| `docs/red/ssh_rapido.sh` | SSH al servidor sin contraseÃ±a | `bash docs/red/ssh_rapido.sh [comando]` |
| `docs/red/verificar_red.sh` | DiagnÃ³stico de red completo | `bash docs/red/verificar_red.sh` |

---

## 13. EjecuciÃ³n

### Verificar estructura (ya completado âœ…):
```bash
python src/00_test_headers.py
```

### Fase 0 â€” ConstrucciÃ³n del Panel:
```bash
# Iniciar el clÃºster Ray:
bash scripts/ray_start.sh all

# Monitor en otra terminal:
bash scripts/monitor_cluster.sh 5

# Ejecutar la construcciÃ³n del panel:
python src/01_construccion_panel.py
```

### Pipeline completo (desde Fase 0):
```bash
python run_pipeline.py --distributed
```
